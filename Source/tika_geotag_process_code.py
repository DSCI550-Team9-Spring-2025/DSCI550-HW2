#This is code to extract geo name entities and their metadata using tika geoparser
#USC
#Spring 2025
#Team 9

## Start Geo NER process

import csv
import subprocess
import tempfile
import os
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock

# Tika configuration paths
TIKA_APP_JAR = "/root/tika/tika-app-2.6.0.jar"
TIKA_NLP_JAR = "/root/tika/tika-parser-nlp-package-2.6.0.jar"
NER_MODEL_DIR = "/root/location-ner-model"
MIME_CONFIG_DIR = "/root/geotopic-mime"

# Input and output files
INPUT_FILE = "/root/v2.geot"  # The input TSV file
OUTPUT_FILE = "/root/v2_with_geo_count.tsv"  # The Output file

# Geo fields to extract from Tika output
#These are the geo meta data generated by the parser
GEO_FIELDS = [
    "Geographic_LATITUDE",
    "Geographic_LONGITUDE",
    "Geographic_NAME"
]

def extract_geo_from_description(geot_content):
    """ Runs the Tika CLI on a given .geot content and extracts geo metadata. """
    with tempfile.NamedTemporaryFile(delete=False, suffix=".geot", mode="w") as tmp_file:
        tmp_file.write(geot_content)
        tmp_path = tmp_file.name

    command = [
        "java",
        "-classpath",
        f"{TIKA_APP_JAR}:{TIKA_NLP_JAR}:{NER_MODEL_DIR}:{MIME_CONFIG_DIR}",
        "org.apache.tika.cli.TikaCLI",
        "-m",
        tmp_path
    ]

    try:
        result = subprocess.run(command, capture_output=True, text=True, check=True)
        geo_data = {field: "" for field in GEO_FIELDS}  # Initialize geo data for base fields
        optional_geo_data = {}  # This will store additional optional fields dynamically
        geo_name_count = 0  # Counter for the number of geo names found

        for line in result.stdout.splitlines():
            # Check for the base geo fields
            for field in GEO_FIELDS:
                if line.startswith(field + ":"):
                    geo_data[field] = line.split(":", 1)[1].strip()
                    if "NAME" in field:
                        geo_name_count += 1

            # Check for optional geo fields dynamically (Optional_LATITUDE1, Optional_LONGITUDE1, etc.)
            if "Optional_LATITUDE" in line or "Optional_LONGITUDE" in line or "Optional_NAME" in line:
                field_name = line.split(":", 1)[0].strip()
                optional_geo_data[field_name] = line.split(":", 1)[1].strip()
                if "NAME" in field_name:
                    geo_name_count += 1

        return geo_data, optional_geo_data, geo_name_count

    except subprocess.CalledProcessError as e:
        print(f"[!] Tika CLI error: {e}")
        return {field: "" for field in GEO_FIELDS}, {}, 0
    finally:
        os.unlink(tmp_path)

def process_row(row, all_fieldnames, progress_counter, progress_lock):
    """ Processes a single row, extracts geo data, and returns the updated row. """
    desc = row.get("description", "")
    geo_name_count = 0
    geo_info = {}
    optional_geo_info = {}

    if desc.strip():
        geo_info, optional_geo_info, geo_name_count = extract_geo_from_description(desc)
        # Update the set of fieldnames with any optional fields
        all_fieldnames.update(geo_info.keys())
        all_fieldnames.update(optional_geo_info.keys())

    row.update(geo_info)
    row.update(optional_geo_info)
    row["GeoName_Count"] = geo_name_count  # Add geo name count for the current row

    # Update progress and print if a multiple of 50 rows is processed
    with progress_lock:
        progress_counter[0] += 1
        if progress_counter[0] % 50 == 0:
            print(f"[+] Processed {progress_counter[0]} rows...")

    return row, geo_name_count

def read_and_process_geot_file():
    """ Generator that reads and processes the input file row by row. """
    with open(INPUT_FILE, newline='', encoding='utf-8') as infile:
        reader = csv.DictReader(infile, delimiter='\t')
        for row in reader:
            yield row

def process_geot_file():
    """ Reads v2.geot, extracts geo metadata, and writes the output file. """
    all_fieldnames = set(GEO_FIELDS)  # Use a set to avoid duplicates
    total_geo_name_count = 0  # Initialize the total geo name count
    progress_counter = [0]  # Counter for rows processed
    progress_lock = Lock()  # Lock to synchronize progress printing

    # Initialize a list to store processed rows, we will update the fieldnames later
    processed_rows = []

    # Process the first row to determine the correct fieldnames and initialize the CSV writer
    first_row = next(read_and_process_geot_file())
    desc = first_row.get("description", "")
    if desc.strip():
        geo_info, optional_geo_info, geo_name_count = extract_geo_from_description(desc)
        all_fieldnames.update(geo_info.keys())
        all_fieldnames.update(optional_geo_info.keys())
        total_geo_name_count += geo_name_count

    # Create a ThreadPoolExecutor to process rows in parallel
    with ThreadPoolExecutor(max_workers=4) as executor:
        futures = []
        for row in read_and_process_geot_file():
            futures.append(executor.submit(process_row, row, all_fieldnames, progress_counter, progress_lock))

        for future in as_completed(futures):
            processed_row, geo_name_count = future.result()
            total_geo_name_count += geo_name_count
            processed_rows.append(processed_row)

            # Update fieldnames to ensure all new fields are included
            all_fieldnames.update(processed_row.keys())

    # Convert all_fieldnames to a sorted list for the CSV writer
    fieldnames = sorted(list(all_fieldnames)) + ["GeoName_Count"]

    # Now write all rows to the output file
    with open(OUTPUT_FILE, 'w', newline='', encoding='utf-8') as outfile:
        writer = csv.DictWriter(outfile, fieldnames=fieldnames, delimiter='\t')
        writer.writeheader()

        # Write all the processed rows
        for processed_row in processed_rows:
            writer.writerow(processed_row)

    # Display the total count of geo names at the end
    print(f"[✓] Done. Output saved to: {OUTPUT_FILE}")
    print(f"[✓] Total geo names found: {total_geo_name_count}")

if __name__ == "__main__":
    process_geot_file()

##End geo NER process

