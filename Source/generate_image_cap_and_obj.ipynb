{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coverting the .CSV file into a .TSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd # type: ignore\n",
    "import requests # type: ignore\n",
    "from tqdm import tqdm # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TSV file to CSV\n",
    "\n",
    "def convert_tsv_to_csv(tsv_file, csv_file):\n",
    "    with open(tsv_file, 'r', newline='', encoding='utf-8') as tsv:\n",
    "        reader = csv.reader(tsv, delimiter='\\t')\n",
    "        with open(csv_file, 'w', newline='', encoding='utf-8') as csv_out:\n",
    "            writer = csv.writer(csv_out, delimiter=',')\n",
    "            for row in reader:\n",
    "                writer.writerow(row)\n",
    "\n",
    "convert_tsv_to_csv('v2.tsv','homework_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image captions saved to image_captions.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "file_path = \"homework_2.csv\"  # Update with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Function to generate image captions based on the conditions\n",
    "def generate_caption(row):\n",
    "    caption = f\"A mysterious event in {row['location']}, {row['city']}, {row['state']}. \"\n",
    "    \n",
    "    if pd.notna(row.get(\"Event\")):\n",
    "        caption += f\"The event was classified as {row['Event'].lower()}. \"\n",
    "    \n",
    "    if pd.notna(row.get(\"Apparition Type\")) and row[\"Apparition Type\"].lower() != \"unknown\":\n",
    "        caption += f\"An apparition of type {row['Apparition Type'].lower()} was reported. \"\n",
    "    \n",
    "    if pd.notna(row.get(\"Apparition Gender\")) and row[\"Apparition Gender\"].lower() != \"unknown\":\n",
    "        caption += f\"The apparition appeared to be {row['Apparition Gender'].lower()}. \"\n",
    "\n",
    "    if pd.notna(row.get(\"time_of_day\")):\n",
    "        caption += f\"The sighting occurred during {row['time_of_day'].lower()}. \"\n",
    "\n",
    "    if pd.notna(row.get(\"Witness Count\")):\n",
    "        caption += f\"{row['Witness Count']} witness(es) reported the phenomenon. \"\n",
    "\n",
    "    if row.get(\"Audio Evidence\") == \"Yes\":\n",
    "        caption += f\"Audio evidence was captured. \"\n",
    "        if pd.notna(row.get(\"Audio Reasoning\")):\n",
    "            caption += f\"The sound analysis suggested: {row['Audio Reasoning']}. \"\n",
    "\n",
    "    if row.get(\"Visual Evidence\") == True:\n",
    "        caption += f\"Visual evidence was obtained. \"\n",
    "        if pd.notna(row.get(\"Visual Reasoning\")):\n",
    "            caption += f\"Experts noted: {row['Visual Reasoning']}. \"\n",
    "\n",
    "    return caption.strip()\n",
    "\n",
    "# Applying the function to generate captions\n",
    "df[\"Image Caption\"] = df.apply(generate_caption, axis=1)\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "output_file = \"image_captions.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Image captions saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests # type: ignore\n",
    "import os\n",
    "\n",
    "url = \"https://api.stability.ai/v1/generation/stable-diffusion-xl-1024-v1-0/text-to-image\"\n",
    "\n",
    "body = {\n",
    "  \"steps\": 40,\n",
    "  \"width\": 1024,\n",
    "  \"height\": 1024,\n",
    "  \"seed\": 0,\n",
    "  \"cfg_scale\": 5,\n",
    "  \"samples\": 1,\n",
    "  \"text_prompts\": [\n",
    "    {\n",
    "      \"text\": \"A painting of a cat\",\n",
    "      \"weight\": 1\n",
    "    },\n",
    "    {\n",
    "      \"text\": \"blurry, bad\",\n",
    "      \"weight\": -1\n",
    "    }\n",
    "  ],\n",
    "}\n",
    "\n",
    "headers = {\n",
    "  \"Accept\": \"application/json\",\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": \"sk-m8GS6Yg8PE7ab93SLBmd7kKRwgMHlD9zqf5J3o3s9PH8ZbbX\",\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "  url,\n",
    "  headers=headers,\n",
    "  json=body,\n",
    ")\n",
    "\n",
    "if response.status_code != 200:\n",
    "    raise Exception(\"Non-200 response: \" + str(response.text))\n",
    "\n",
    "data = response.json()\n",
    "\n",
    "# make sure the out directory exists\n",
    "if not os.path.exists(\"./out\"):\n",
    "    os.makedirs(\"./out\")\n",
    "\n",
    "for i, image in enumerate(data[\"artifacts\"]):\n",
    "    with open(f'./out/txt2img_{image[\"seed\"]}.png', \"wb\") as f:\n",
    "        f.write(base64.b64decode(image[\"base64\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 10980/10980 [3:09:39<00:00,  1.04s/it] \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_best_caption(image_path, beam_size=6):\n",
    "    # Use endpoint to change the beamsize/output\n",
    "    TIKA_CAPTION_ENDPOINT = f\"http://localhost:8764/inception/v3/caption/image?beam_size={beam_size}\"\n",
    "    try:\n",
    "        with open(image_path, 'rb') as f:\n",
    "            response = requests.post(\n",
    "                TIKA_CAPTION_ENDPOINT,\n",
    "                headers={'Accept': 'application/json'},\n",
    "                data=f\n",
    "            )\n",
    "    except Exception as e:\n",
    "        return f\"Exception when processing {image_path}: {e}\"\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            data = response.json()\n",
    "            captions = data.get('captions', [])\n",
    "            if captions:\n",
    "                # pick up only most confident/relevant caption\n",
    "                best_caption = max(captions, key=lambda x: x[\"confidence\"])\n",
    "                return best_caption['sentence']\n",
    "            else:\n",
    "                return \"No valid caption found\"\n",
    "        except ValueError:\n",
    "            return \"Failed to parse JSON\"\n",
    "    else:\n",
    "        return f\"Error {response.status_code} - {response.text}\"\n",
    "\n",
    "# load in the dataset\n",
    "# CHANGE TO YOUR RESPECTIVE CSV PATH\n",
    "file_path = \"image_captions_with_paths_desc.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Uncomment the following line to use a random sample of 20 rows\n",
    "# df = df.sample(20, random_state=25)\n",
    "\n",
    "# process each image in the dataset with a progress bar\n",
    "captions = []\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing images\"):\n",
    "    # PUT IN REAL IMG PATH/COL NAME FROM DF\n",
    "    image_path = row['Image Path']\n",
    "    caption = get_best_caption(image_path)\n",
    "    captions.append(caption)\n",
    "\n",
    "# add captions to the DF. Name col as please.\n",
    "df['caption'] = captions\n",
    "\n",
    "# Save the updated DF to CSV\n",
    "output_path = \"hw_2_with_images_and_captions.csv\"\n",
    "df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 10980/10980 [54:28<00:00,  3.36it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objects saved to hw2_with_captions_and_objects.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Configuration ---\n",
    "CSV_PATH = 'hw_2_with_images_and_captions.csv'  # your input CSV file\n",
    "OUTPUT_PATH = 'hw2_with_captions_and_objects.csv'  # output CSV\n",
    "OBJECTS_ENDPOINT = 'http://localhost:8764/inception/v4/classify/image'\n",
    "\n",
    "# --- Object Detection Function ---\n",
    "def get_objects(image_path):\n",
    "    try:\n",
    "        with open(image_path, 'rb') as f:\n",
    "            response = requests.post(\n",
    "                OBJECTS_ENDPOINT,\n",
    "                headers={'Accept': 'application/json'},\n",
    "                data=f\n",
    "            )\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            return ', '.join(data.get('classnames', []))\n",
    "        else:\n",
    "            print(f\"Object detection error {response.status_code} for {image_path}\")\n",
    "            return ''\n",
    "    except Exception as e:\n",
    "        print(f\"Object detection exception for {image_path}: {e}\")\n",
    "        return ''\n",
    "\n",
    "# --- Step 1: Read CSV ---\n",
    "df = pd.read_csv(CSV_PATH, encoding='utf-8')\n",
    "\n",
    "# --- Step 2: Process Objects ---\n",
    "objects = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing images\"):\n",
    "    # Assumes you have a column named 'Image Path'\n",
    "    image_path = row['Image Path']\n",
    "    \n",
    "    if os.path.exists(image_path):\n",
    "        detected_objects = get_objects(image_path)\n",
    "    else:\n",
    "        print(f\"Image not found: {image_path}\")\n",
    "        detected_objects = ''\n",
    "    objects.append(detected_objects)\n",
    "\n",
    "# --- Step 3: Save ---\n",
    "df['objects'] = objects\n",
    "df.to_csv(OUTPUT_PATH, index=False)\n",
    "print(f\"Objects saved to {OUTPUT_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
